{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A clean(er) version of FaceMatch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import image\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from random import randrange\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "## Load Data\n",
    "#### Data Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_images_per_pos_image = 10\n",
    "image_shape = (32, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read an image from a path to a tensor and put it in the correct format\n",
    "def load_image_to_tensor(path):\n",
    "    img = image.imread(path)\n",
    "    resize = cv2.resize(img, image_shape)\n",
    "    tensor = torch.tensor(resize, device=dev)\n",
    "    # put in N Channel Height Width format!\n",
    "    permute = tensor.permute(2,0,1)\n",
    "    return permute\n",
    "\n",
    "# concatenates two images for input to the model\n",
    "def make_input_from_images(img_a, img_b):\n",
    "    cat = torch.cat((img_a, img_b), dim = 2)\n",
    "    return cat\n",
    "\n",
    "# generates an image from a pair of paths as stored in X in data\n",
    "def make_input_from_paths(x):\n",
    "    img_a = load_image_to_tensor(x[0])\n",
    "    img_b = load_image_to_tensor(x[1])\n",
    "    return make_input_from_images(img_a, img_b)\n",
    "\n",
    "# removes incorect files from an array of paths\n",
    "def remove_ds(files):\n",
    "    for f in files:\n",
    "        if '.DS' in f:\n",
    "            files.remove(f)\n",
    "    return files\n",
    "\n",
    "# show an example a dataset at a given index\n",
    "def show_example(dataset, idx):\n",
    "    idx_x, idx_y = dataset.__getitem__(idx)\n",
    "    title = '\\033[92m Positive Example \\033[0m' if idx_y == 1 else '\\033[93m Negative Example \\033[0m'\n",
    "    print(title)\n",
    "    plt.imshow(idx_x.cpu().permute(1,2,0).int())\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Dataset from Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a Dataset for use with a DataLoader\n",
    "# Reads all images in a given folder into a dataset with given parameters\n",
    "class FaceMatchDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, directory, negative_examples_per_image=10):\n",
    "        '''generate examples based on files'''\n",
    "        x = np.array([[]])\n",
    "        y = np.array([])\n",
    "        people_images_dict = {}\n",
    "        \n",
    "        # each folder contains a list of people\n",
    "        people_folders = os.listdir(directory)\n",
    "        people_folters = remove_ds(people_folders)\n",
    "        \n",
    "        for person_folder in people_folders:\n",
    "            images = os.listdir(directory + '/' + person_folder)\n",
    "            images = remove_ds(images)\n",
    "            image_paths = [] \n",
    "            for image in images:\n",
    "                    image_paths.append(directory + '/' + person_folder + '/' + image)\n",
    "\n",
    "            people_images_dict[person_folder] = image_paths\n",
    "        \n",
    "        for person in people_images_dict.keys():\n",
    "            # get positive images\n",
    "            positive_images = people_images_dict[person]\n",
    "    \n",
    "            # get negative images\n",
    "            people_images_dict_keys = list(people_images_dict.keys())\n",
    "            people_images_dict_keys.remove(person)\n",
    "            negative_images = []\n",
    "\n",
    "            for k in people_images_dict_keys:\n",
    "                negative_images = negative_images + people_images_dict[k]\n",
    "                \n",
    "            #for each image\n",
    "            for first_pos_image in positive_images:\n",
    "\n",
    "                #make positive examples\n",
    "                for second_pos_image in positive_images:\n",
    "                    \n",
    "                    positive_example = np.array([[first_pos_image, second_pos_image]])\n",
    "                    if (x.size == 0):\n",
    "                        x = positive_example\n",
    "                    else:\n",
    "                        x = np.append(x, positive_example, axis=0)\n",
    "                    y = np.concatenate((y, [1]))\n",
    "            \n",
    "                #make negative examples\n",
    "                for i in range(negative_examples_per_image):\n",
    "                    random_negative_image_filename = negative_images[randrange(len(negative_images))]\n",
    "                    if randrange(3) == 0:\n",
    "                        negative_example = np.array([[random_negative_image_filename, first_pos_image]])\n",
    "                        x = np.append(x, negative_example, axis=0)\n",
    "                        y = np.concatenate((y, [0]))\n",
    "                    else:\n",
    "                        negative_example = np.array([[first_pos_image, random_negative_image_filename]])\n",
    "                        x = np.append(x, negative_example, axis=0)\n",
    "                        y = np.concatenate((y, [0]))\n",
    "            \n",
    "        \n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        #return the number of examples\n",
    "        return self.x.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        #make the example for the index\n",
    "        idx_x = make_input_from_paths(self.x[idx])\n",
    "        idx_y = torch.Tensor([self.y[idx]])\n",
    "        \n",
    "        return idx_x.float(), idx_y.float()\n",
    "    \n",
    "    def get_x_length(self):\n",
    "        return self.x.shape[0]\n",
    "    \n",
    "    def get_y_length(self):\n",
    "        return self.y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Genereate Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FaceMatchDataset('TrainCroppedDataset', negative_examples_per_image=negative_images_per_pos_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = FaceMatchDataset('TestCroppedDataset', negative_examples_per_image=negative_images_per_pos_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Data\n",
    "#### Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset Length: 35542 items\n",
      "Test Dataset Length: 1840 items\n"
     ]
    }
   ],
   "source": [
    "print('Train Dataset Length: ' + str(train_dataset.__len__()) + ' items') \n",
    "print('Test Dataset Length: ' + str(test_dataset.__len__()) + ' items') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View at Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m Negative Example \u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = train_dataset\n",
    "# dataset = test_dataset\n",
    "idx = randrange(dataset.__len__())\n",
    "# idx = 6\n",
    "show_example(dataset, idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "## Build Model\n",
    "#### Network Utilities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_example(example):\n",
    "    x, y = example\n",
    "    net_inpt = torch.unsqueeze(x, 0)\n",
    "    pred = model(net_inpt.float())\n",
    "\n",
    "    print('\\033[92mCorrect!\\033[0m' if round(pred.detach().numpy()[0][0]) == y else '\\033[93mWrong!\\033[0m')\n",
    "    print(('Positive Example' if y == 1 else 'Negative Example') + ' Prediction: ' + str(pred.detach().numpy()[0][0]))\n",
    "    \n",
    "    plt.imshow(x.permute(1,2,0).int())\n",
    "    plt.show()\n",
    "    \n",
    "# Returns the % correct, number negative examples wrong, and the number positive examples wrong\n",
    "def compute_average_acuracy_for_dataset(ds):\n",
    "    model.eval()\n",
    "    test_loader = torch.utils.data.DataLoader(ds, batch_size=64)\n",
    "    y_hat = torch.Tensor([])\n",
    "    y = torch.Tensor([])\n",
    "\n",
    "    for batch_idx, (mini_x, mini_y) in enumerate(test_loader):\n",
    "        with torch.no_grad():\n",
    "            mini_y_hat = model(mini_x)\n",
    "        y_hat = torch.cat((y_hat, mini_y_hat.cpu()))\n",
    "        y = torch.cat((y, mini_y))\n",
    "\n",
    "    num_right = 0\n",
    "    num_neg_wrong = 0\n",
    "    num_pos_wrong = 0\n",
    "    for i in range(y.shape[0]):\n",
    "        if round(y_hat[i].detach().numpy()[0]) == y[i]:\n",
    "            num_right += 1\n",
    "        elif y[i] == 0:\n",
    "            num_neg_wrong += 1\n",
    "        else:\n",
    "            num_pos_wrong += 1\n",
    "    return num_right / y.shape[0] * 100, num_neg_wrong, num_pos_wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "# 3 convolutional layers followed by 2 fully connected layers\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # layer 1\n",
    "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 8, kernel_size = 3, padding = 1)\n",
    "        self.a1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size = 2)\n",
    "        #norm???\n",
    "        # layer 2\n",
    "        self.conv2 = nn.Conv2d(in_channels = 8, out_channels = 16, kernel_size = 3, padding = 1)\n",
    "        self.a2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size = 4)\n",
    "        # layer 3\n",
    "        self.conv3 = nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size = 3, padding = 1)\n",
    "        self.a3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size = 4)\n",
    "        #linear\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(in_features = 64, out_features = 32)\n",
    "        self.a4 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(in_features = 32, out_features = 1)\n",
    "        self.a5 = nn.ReLU()\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        # layer 1\n",
    "        x = self.conv1(x)\n",
    "        x = self.a1(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        # layer 2\n",
    "        x = self.conv2(x)\n",
    "        x = self.a2(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        #layer 3\n",
    "        x = self.conv3(x)\n",
    "        x = self.a3(x)\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        #linear\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.a4(x)\n",
    "        x = self.fc2(x)\n",
    "#         x = torch.tanh(x)\n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "model.to(dev);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "#### Train Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_epochs = 20\n",
    "# learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 1 / 20\r"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "optimizer = optim.Adadelta(model.parameters(), weight_decay = 1e-3)\n",
    "loss_function = nn.MSELoss(reduction='sum')\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('Training Epoch ' + str(epoch + 1) + ' / ' + str( num_epochs), end='\\r')\n",
    "    \n",
    "    for batch_idx, (mini_x, mini_y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        mini_y_hat = model(mini_x.to(dev))\n",
    "        loss = loss_function(mini_y_hat.cpu(), mini_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = train_statset\n",
    "# dataset = test_dataset\n",
    "idx = randrange(dataset.__len__())\n",
    "# idx = 8\n",
    "test_example(dataset.__getitem__(idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Entire Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 53.91304347826087% Missed Positives: 288 Missed Negatives: 560\n"
     ]
    }
   ],
   "source": [
    "# dataset = train_dataset\n",
    "dataset = test_dataset\n",
    "per, nnw, npw = compute_average_acuracy_for_dataset(dataset)  \n",
    "print('Accuracy: ' + str(per) + '%' + ' Missed Positives: ' + str(npw) + ' Missed Negatives: ' + str(nnw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
